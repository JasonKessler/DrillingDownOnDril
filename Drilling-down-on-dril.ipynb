{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drilling down on @Dril\n",
    "\n",
    "> \"getting pisse d off imagining my trolls and dissenters crawling around my house in little butler outfits and expecting tips\" \n",
    "\n",
    "-- @dril, after his recent doxing.  Retweeted more than 3,800 times and liked more than 32,000 times.\n",
    "\n",
    "What, in the land of weird Twitter, makes @dril @dril?\n",
    "\n",
    "We can use the Python tool Scattertext to shed light on @dril's unique style and compare his Tweets to others in the weird Twitter space.\n",
    "\n",
    "We'll first use Tweepy to pull the corpus of @dril's tweets.  In order to examine his style futher, we'll pull tweets from other weird Twitter users as a comparison corpus.  \n",
    "\n",
    "Given @dril's propensity to mention other weird Twitter users, we can download the timelines of other wierd Twitter users as a comparison corpus.\n",
    "\n",
    "## Technique\n",
    "\n",
    "We'll use the Scattertext Python package to create the visualizations. See an overview on https://github.com/JasonKessler/scattertext\n",
    "\n",
    "If you use the package, please cite it as:\n",
    "\n",
    "Jason S. Kessler. Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ. ACL System Demonstrations. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminary imports\n",
    "\n",
    "%matplotlib inline\n",
    "import twitter, tweepy\n",
    "import scattertext as st\n",
    "import re, io, itertools\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os, pkgutil, json, urllib, datetime, time, itertools\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "import warnings\n",
    "import functools\n",
    "import collections\n",
    "from html.parser import HTMLParser\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Twitter API connection using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secret_key, consumer_key = os.environ['TWITTER_SECRET_KEY'], os.environ['TWITTER_CONSUMER_KEY']\n",
    "access_token, token_secret = os.environ['TWITTER_ACCESS_TOKEN'], os.environ['TWITTER_TOKEN_SECRET']\n",
    "api = twitter.Api(consumer_key=consumer_key,\n",
    "                  consumer_secret=secret_key,\n",
    "                  access_token_key=access_token,\n",
    "                  access_token_secret=token_secret)\n",
    "auth = tweepy.OAuthHandler(consumer_key, secret_key)\n",
    "auth.set_access_token(access_token, token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Some helper functions for pulling statuses, assembling them into data frames, and extraction mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pull_statuses(screen_name, verbose=False, last_id = None):\n",
    "    pages = []\n",
    "    try:\n",
    "        for page in tweepy.Cursor(api.user_timeline, screen_name=screen_name).pages():\n",
    "            if verbose: print(len(page))\n",
    "            pages.append(page)\n",
    "    except Exception as e:\n",
    "        print(screen_name, e)\n",
    "        \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataframe_from_pages(pages):\n",
    "    html_parser = HTMLParser()\n",
    "\n",
    "    df = pd.concat([pd.DataFrame([x._json for x in page]) for page in pages]).reset_index()\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['retweet_filtered_text'] = (df\n",
    "                                   .text\n",
    "                                   .apply(lambda x: html_parser.unescape(' '.join(x.split()[2:]) \n",
    "                                                                         if x.startswith(\"RT \") \n",
    "                                                                         else x)))\n",
    "    df['parse'] = df['retweet_filtered_text'].apply(nlp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_mention_counts(tweets):\n",
    "    mentions = collections.Counter(\n",
    "        functools.reduce(lambda a, b: a + b, \n",
    "                         (dril_status_df[tweets.apply(lambda x: type(x) == str)]\n",
    "                          .text\n",
    "                          .apply(lambda x: [t for t in x.lower().split() \n",
    "                                            if t.startswith('@') and len(t) > 2])))\n",
    "    )\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pull @dril's timeline to the Pandas dataframe dril_status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dril_status_df = dataframe_from_pages(pull_statuses('dril'))\n",
    "dril_status_df['screen_name'] = 'dril'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the users @dril mentions frequently to identify other weird Tweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@nataliejmooney', 34), ('@machiavellino', 29), ('@neonwario', 25), ('@mcdonalds', 24)]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "mentions = extract_mention_counts(dril_status_df.text)\n",
    "print(mentions.most_common(4))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many are inaccessible or not right for the comparison set.\n",
    "\n",
    "- ~~@nataliejmooney~~ (proteced)\n",
    "- ~~@machiavellino~~ (suspended)\n",
    "- @neonwario \n",
    "- ~~@mcdonalds~~ (a corporation)\n",
    "- @celiapienkosz\n",
    "- @bronzehammer\n",
    "    - @_hermit_thrush_\n",
    "- ~~@respected_loner~~ (proteced)\n",
    "- @adultblackmale\n",
    "- ~~@dril~~ (@dril)\n",
    "- ~~@sofieok~~ (protected)\n",
    "- @911victim\n",
    "- @dinkmagic\n",
    "- ~~@dwayne274928572~~ (deleted)\n",
    "- @bakkooonn\n",
    "- @leyawn\n",
    "- @hermit_thrush\n",
    "- ~~@hizzaerd~~ (protected)\n",
    "- ~~@bashfulcoward~~ (suspended)\n",
    "- @bevissimpson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We were able to download statuses for five users before I exceeded my API's limit :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911victim Twitter error response: status code = 429\n",
      "dinkmagic Twitter error response: status code = 429\n",
      "bakkooonn Twitter error response: status code = 429\n",
      "leyawn Twitter error response: status code = 429\n",
      "hermit_thrush Twitter error response: status code = 429\n",
      "bevissimpson Twitter error response: status code = 429\n"
     ]
    }
   ],
   "source": [
    "weird_tweeps = ['neonwario', 'celiapienkosz', 'bronzehammer', '_hermit_thrush_', \n",
    "                'adultblackmale', '911victim', 'dinkmagic', 'bakkooonn',\n",
    "                'leyawn', 'hermit_thrush', 'bevissimpson']\n",
    "other_statuses = []\n",
    "for user in weird_tweeps:\n",
    "    try:\n",
    "        other_statuses.append(pull_statuses(user))\n",
    "    except:\n",
    "        print('Cannot pull statuses from', user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the other statuses into a data frame, label statuses with screen names, and concatenate all statuses into one big data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_status_df = pd.concat([dataframe_from_pages(page) \n",
    "                             for page in other_statuses \n",
    "                             if len(page)]).reset_index(drop=True)\n",
    "other_status_df['screen_name'] = other_status_df['user'].apply(lambda x: x['screen_name'])\n",
    "all_status_df = pd.concat([dril_status_df, other_status_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove tweets that are retweets or have less than 20 characters, and drop duplicate statuses\n",
    "Save data frame to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_status_df = all_status_df.loc[all_status_df\n",
    "                                  .text\n",
    "                                  .drop_duplicates()\n",
    "                                  .apply(lambda x: len(x) > 20 and not x.startswith('RT '))\n",
    "                                  .index]\n",
    "all_status_df.to_csv('all_status_df.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kesslej/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# reread archived statuses\n",
    "try:\n",
    "    all_status_df\n",
    "except:\n",
    "    all_status_df = pd.read_csv('all_status_df.csv.gz', compression='gzip')\n",
    "    all_status_df['parse'] = all_status_df['retweet_filtered_text'].apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble into Scattertext corpus, with the category being screen name.  \n",
    "Omit mentions, and words with apostrophes in them.  Dril's lack of apostrophes messes up the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (st.CorpusFromParsedDocuments(all_status_df, \n",
    "                                       category_col='screen_name', \n",
    "                                       parsed_col='parse')\n",
    "          .build())\n",
    "corpus = corpus.remove_terms([t \n",
    "                              for t in corpus.get_term_freq_df().index \n",
    "                              if ('@' in t or \"'\" in t or \"’\" in t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm = corpus.get_term_freq_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scattertext plot\n",
    "\n",
    "It's clear that @dril, uniquely, has a potty mouth.  The top scaled-F-scoring terms are profane, scatalogical, and related to social media (feed, trolls, followers, content , user, etc...). Terms are colored by scaled-F-score.\n",
    "\n",
    "Please see https://github.com/JasonKessler/scattertext for more information on the metric.\n",
    "\n",
    "While @dril tends to make gendered references to people using \"boys\" and \"girls\", other weird Twitter users prefered the term \"dudes\".  @dril doesn't use acronyms like \"btw\", \"lol\", or \"ftw\" as other weird twitter users do.  He also doesn't call things \"crazy\" like other weird Twitter users do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"700\"\n",
       "            src=\"output/dril_vs_non.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x152e9c5f8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = '@' + all_status_df['screen_name'] + ' ' + all_status_df['created_at'].astype(str)\n",
    "html = st.produce_scattertext_explorer(corpus,\n",
    "                                       category='dril',\n",
    "                                       category_name='@Dril',\n",
    "                                       not_category_name='Not @Dril',\n",
    "                                       use_full_doc=True,\n",
    "                                       minimum_term_frequency=20,\n",
    "                                       minimum_not_category_term_frequency=20,\n",
    "                                       pmi_filter_thresold=6,\n",
    "                                       term_ranker=st.termranking.OncePerDocFrequencyRanker,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       metadata=metadata,\n",
    "                                       sort_by_dist=False)\n",
    "\n",
    "file_name = 'output/dril_vs_non.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative visualization\n",
    "We can instead use log-odds-ratio with an uniformaitive prior (see Monroe et. al (2009) for more details) to visualize lanaguage differences\n",
    "\n",
    "Here, the x-axis is the log-freqeuency of a term, and the y-axis shows the association a term.  This technique can favor function words over content terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"700\"\n",
       "            src=\"output/dril_vs_non_lorup.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x152e2f320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_fightin_words_explorer(corpus,\n",
    "                                         category='dril',\n",
    "                                         category_name='@Dril',\n",
    "                                         not_category_name='Not @Dril',\n",
    "                                         use_full_doc=True,\n",
    "                                         minimum_term_frequency=20,\n",
    "                                         minimum_not_category_term_frequency=20,\n",
    "                                         pmi_filter_thresold=6,                                         \n",
    "                                         term_ranker=st.termranking.OncePerDocFrequencyRanker,\n",
    "                                         width_in_pixels=1000,\n",
    "                                         metadata=metadata)\n",
    "file_name = 'output/dril_vs_non_lorup.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=700)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
